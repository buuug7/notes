# 大 O 表示法

描述算法复杂度时, 常用 O(T(n)) 表示对应算法的时间复杂度, 是算法的时空复杂度的表示. 不仅仅用于表示时间复杂度, 也用于表示空间复杂度.

O 后面的括号中有一个函数, 指明某个算法的耗时/耗空间与数据增长量之间的关系. 其中的 n 代表输入数据的量.

- 描述的是最糟糕情况下的运行时间
- 它关心的是你的算法在较大输入情况下的耗时/耗空间情况, 而不是关心你的算法在小量输入情况下表现的如何好

## 常用的算法复杂度表示

#### Constant time 常量时间 O(1)

所需要的操作数与输入无关, 无论输入数据增大多少倍, 耗时/耗空间都不变. 例如哈希算法, 根据索引访问数组元素等.

#### Logarithmic time 对数时间 O(log n)

所需要的操作数与输入大小成对数关系, 当数据增大 n 倍时, 耗时增大 log n 倍(这里的 log 通常以 2 为底的, 比如当数据增大 256 倍时, 耗时只增大 8 倍, 是比线性还要低的时间复杂度). 例如二分查找, 每一次排除一般的可能.

#### Square-root time 平方根时间 O(sqrt(n))

所需要的操作数与输入大小成平方根关系.

#### Linear time 线性时间 O(n)

所需要的操作数与输入大小成正比, 耗时/耗空间随着输入呈线性增长, 数据量增大几倍, 耗时也增大几倍. 例如对集合的迭代, 遍历算法, 线性搜索, 在数组中查找最大/最小值等.

#### Log-linear time 对数线性时间 O(n log n)

所需要的操作数跟输入大小成 `n * (log n)` 关系, 对数的底数无关紧要, 通常用 2 作为底数. 当数据增大 256 倍时, 耗时增大 `256 * 8 = 2048` 倍. 这个复杂度高于线性低于平方, 归并排序就是该时间复杂度.

#### Quadratic time 二次方时间 O(n^2)

所需要的操作数与输入大小成二次方关系, 就代表数据量增大 n 倍时, 耗时增大 n 的平方倍, 这是比线性更高的时间复杂度. 比如冒泡排序, 就是典型的 O(n^2)的算法, 对 n 个数排序, 需要扫描 `n * n` 次. 还有选择排序, 插入排序等.

#### Exponential time 指数时间 O(2^n)

所需要的操作数与输入大小成指数关系, 增长非常快, 例如旅行商问题的解决方案.
